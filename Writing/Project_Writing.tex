% ----------------------------------------------------------------
% Report Class (This is a LaTeX2e document)  *********************
% ----------------------------------------------------------------
% ACS 322/420 Dissertation Template
% March 2013, JL

\documentclass[12pt,a4paper]{report}
\usepackage[lmargin=3.81cm,tmargin=2.54cm,rmargin=2.54cm,bmargin=2.52cm]{geometry}
\linespread{1.5}
% Fonts -- the following two packages give your Times Roman in LaTex
%\usepackage{txfonts}
\usepackage{mathptmx}
\usepackage{mathtools} %argmin
\usepackage{verbatim} 
\usepackage{algorithmic}
\usepackage{relsize}

\usepackage{graphicx}
\usepackage{subcaption}
%\usepackage[nottoc]{tocbibind} 
\usepackage{apacite}
%\graphicspath{ {/Users/PureMac/Desktop/Learning_Analytics/Figs/} }
\graphicspath{ {Figs/} }

\begin{document}

\pagenumbering{Roman}

\newpage \section*{ABSTRACT}

% This section is compulsory -- guidelines can be found in the presentation about writing the dissertation.

\newpage \section*{ACKNOWLEDGEMENTS}


%%% Table of Contents

\tableofcontents

\thispagestyle{empty}


% ======================================================== %
%		1. Introduction
% ======================================================== %
\chapter{Introduction}

\pagenumbering{arabic}
\setcounter{page}{1}

% ======================================= %
%		1.1 Background and Motivation
% ======================================= %
\section{Background and Motivation}

% Conditioning paradigms reflects the "neurobiological basis of learning and memory" (Gallistel 2004).  
Learning curves may reflect different underlying learning processes. For example, in insight learning, it may follow slightly fluctuated level and sudden dramatic increase at some points. Because the learning is sometimes the result of experience through personal interactions with the environment. And following the occurrence of insight, abrupt realisation of how to solve the problem can be repeated in future similar situations. This means that the associated experiences with insights can be parameterised, and it can be linked to future behaviours.
% Also, experiences and insight may reinforce each other and can be associated to one another. This associated experience can be memorised and be a feedback as a parameter for future learning. 
% Eventually, behaviour can memorise stimuli and feedbacks, and these may affect and eventually change behaviour.
% insight learning, associative learning, multi-component/process learning.

% These learning processes are reinforced by the conditioned stimulus
% Insight learning is the first cognitive learning.  
% https://psychlopedia.wikispaces.com/insight+learning

%Associative learning : a learning principle that states ideas and experiences reinforce each other and can be mentally linked to one another. Conditioning; behaviour can be modified or learned based on a stimulus and a response. Reinforcers; stimuli used to change behaviour.

Therefore, there are several possible functions which might fit learning curves and represent different learning processes; step function, powerlaw, piecewise powerlaw and etc. Through possible functions and learning curves, people can be grouped into several learning patterns. Moreover, by inspecting people in those groups, 'how they practice' to get the learning curve and 'which features' having an affect upon individuals can be found. Then suggestions for better learning for individuals may be categorised and proposed.

% By fitting those functions to the big data of individuals' game result with various features,
% may influence the individuals' learning curve' 
% on their learning process'

For this, online games are a reasonable instrument. As it involves "rapid perception, decision making, and motor responding", as well as it gives rich details of practice history, in order to find individuals' learning curve and investigate their features (Stafford and Dewar, 2013) 

%\textit{An online game involving rapid perception, decision making, and motor responding. Use of game data-> rich details of training history with measures of performance. Relations between \textbf{practice amount} and \textbf{subsequent performance}, and between \textbf{practice spacing} and \textbf{subsequent performance.}\\
%Greater initial variation in performance is linked to higher subsequent performance-> \textbf{a result we link to the exploration/exploitation trade-off from the computational framework of reinforcement learning.}//
%Explaining two dilemmas: \\
%Reinforcement learning, exploration/exploitation dilemma}

% \subsection{[level 3 heading]}

% As a general rule don't use more than three levels for a heading

Text...

% ======================================= %
%		1.2. Problem Definition
% ======================================= %

\section{Problem Definition}

There are three main issues in traditional reinforcement learning curve. Because it has smooth power law with diminishing gain derived from average value, all possible individual learning curve are squashed into one learning curve. Thus, it cannot tell which learning curve will belong to a task, behaviour, and learning process. Furthermore, even though identifying bad or good on learnings are important, but it cannot provide sufficient information about those.

Below is the list of problems on current reinforcement learning curve.

\begin{itemize}
\item Not being able to categorise learning process.
\item Averaging possible individual learning curves
\item Not enough information for identification of learning success
\end{itemize}
%Explaining about the problem of bootstrapping analysis.\\
%https://en.wikipedia.org/wiki/Bootstrapping (statistics)\\
% "Unless one is reasonably sure that the underlying distribution is not heavy tailed, one should hesitate to use the naive bootstrap"\\
%Bootstrap of the mean in the infinite variance case Athreya, K.B. Ann Stats vol 15 (2) 1987 724-731\\

%%%%%%%%%%%%%%%%%%%
% Piecewise powerlaw? ????? ??? ???? ??? curve? ?? ???? 
% ??? ? ????!
%%%%%%%%%%%%%%%%%%%

% This is a suggested section heading

% ======================================= %
%		1.3. Aims and Objectives
% ======================================= %

\section{Aims and Objectives}
%%%%%
These are the concepts I think you should cover in your introduction:

Skill acquisition \& expertise
- factors which are known to influence skill acquisition
- practice amount, practice spacing, others

Using games to study skill acquisition

Learning curves
- different possible underlying functions
- problems with averaging over

The ultimate aim, of course, is to identify individuals who learn faster or for longer, and try and relate this to how they practice
%%%%%
The aim of this paper is to fit different functions to the Axon game data. In the data, there are 854,064 individuals data about when, where they did the game and other informations, as well as scores of game according to their attempts. And so identify the underlying learning process. Furthermore, it is to inspect features which may have influences on the learning curves. 

\begin{itemize}
\item Understand several possible functions; step function, powerlaw, piecewise powerlaw and etc.
\item Understand different underlying learning processes; insight learning, associative learning, multi-component/process learning and etc.
\item Fit functions to individual Axon game data and compare those to identify.
\item Test theories of what makes learning most effective, exploiting unsupervised learning, establish which parameter is important for getting learning curve from the data.
\item Design more effective learning practices.
\end{itemize}
% This section is compulsory -- guidelines can be found in the presentation about writing the dissertation

%The aim(s) should provide a general idea of what the project is about and the objectives should be more specific. The objectives should be actions that you expect to do (e.g. simulate..., test..., compare...). At the end of the project it should be possible to assess which of the objectives have been achieved. The objectives will also link into the work programme (below).

% ======================================= %
%		1.4. Project Management
% ======================================= %

\section{Project Management}

% This section is compulsory -- guidelines can be found in the presentation about writing the dissertation

Text...

% ======================================================== %
%		2. Data Curation
% ======================================================== %


\chapter{Data Curation}
A large number of data were acquired through the online game named Axon which is developed by Preload for Welcome trust \cite{stuart2009Axon}. In total 1,201,516 machine identities (or players) played the game over 4 million times. The raw data set is fundamentally comprised by the score, date, time of plays and so on in accordance with machine identities which may represent each individual. %\cite{stafford2014tracing}. 
Undoubtedly, it can be possible to extract information from the data set on how people practised to get a higher score. For example, it shows how much time they played for each score. 
However, the raw data set of on-line game seems quite noisy to discern those factors which affect player's learning. It contained many 'undefined' or 'unrepresentable values', and some values are not valid, such as the starting play time is later than the time play finished. For this reason, the information on what the analysis needs cannot be identified directly from it.

Thus, the data source needs refining processes until the gemstone of data set could gleam with the evidence of valuable information. In other words, the big data set has to be curated. Stonebraker et al. stated that "data curation is the act of discovering a data source(s) of interest, cleaning and transforming the new data, semantically integrating it with other local data sources, and deduplicating the resulting composite" \cite{stonebraker2013data}.

\bigskip
Below are the tasks in which steps of data curation are largely expected,

% that this dissertation is interested in, and especially where
\begin{enumerate}
	\item Cleaning raw data set,
	%\item Grouping filtered data set according to the same machine ID,
	\item Incrementally accommodating new data entities,
	\item Normalising scores grouped by the same players,
	\item Clustering players, showing the similar patterns.
\end{enumerate}

In particular, data curation tasks followed methods of two previous studies
\cite{stafford2014tracing, stafford2016testing}.
Accordingly, the curation tasks of cleaning, grouping by machine IDs and accommodating will be explained in the following section. After that, other tasks for data deformation and clustering will be examined.

\begin{comment}
which certified "the relationship between the practice amount and subsequent performance, and between practice spacing and subsequent performance" and "the consolidation effect for skill learning". In order for these analyses, unnecessary information contained in the data set had to be filtered, and additionally, the new variables were augmented by manifesting some hidden features in the same player through those two analyses.

In gratitude, filtering methods on the data source was already regularized in some degree by Stafford et al. (2014; 2016).
\end{comment}
% , K-Means clustering, with the artificial neural network algorithm, competitive learning 

% ======================================= %
%		2.1. Data Cleaning
% ======================================= %
\section{Data Cleaning}

What has to be noted before data cleaning is that it has to be implemented under the grouped data by the same machine IDs. In toal 4,038,802 plays were sorted by players having the same machine IDs, and then 1,201,516 players were detected. The criteria according to the previous two studies \cite{stafford2014tracing, stafford2016testing} are as follow,
% Though the two studies in 2014 and 2016 about skill learning analysis using the game data source, some curation steps were performed by the following criteria.

%\begin{itemize}
%	\item 26,727 players who did not play a minimum of 15 games were eliminated,
%	\item 8\% out of the total number of players attempted more than 300 times, and those were also discharged.
%	\item 26,175 data which lack valid longitude or timing information for each attempt were filtered.
%\end{itemize}

\begin{enumerate}
	\item players who did not play at least 15 games,
	\item players who attempted more than 300 times,
	\item data which lack valid longitude or timing information for each attempt,
	\item players with discontinuous game play attempts.
\end{enumerate}

The reason of discarding those who played less than 15 attempts is because those cannot show a causal relationship between attempts and scores. In this step, xxx individuals were deleted. 
The reason for second step is that plays more than 300 attempts did not show many differences after 300 attempts. ??? out of the total number of players attempted the game more than 300 times, and also they were removed. Also discarded players having unrecognisable time information were ???. Finally, game play data for individuals were recorded discontinuously. In other words, there are non-recorded game play data between the first attempt and the last attempt for each players. The reason why this problem happened is unknown, though it is obvious that individuals with this issue have to be filtered appropriately. Though cleaning those is simply mentioned in this session, the specific method how to manage players with discontinuous data will be discussed in chapter ???.

As a result, raw data with 4, 038,802 plays with xxx players were cleaned, and then reduced to ??? plays and ??? individuals decreased by ???.

\section{Data accommodating}
The next step of data curation is to incrementally accommodate hidden but obvious features from the previous cleaned data set. It is originally constituted by 8 basic categories. After data accommodating task, 7 additional hidden variables would be derived.

\subsection{Original variables in the data source}
When people play the on-line game, 7 basic features as follow is recorded,
\begin{itemize}
    \item machine identities,
	\item scores and attempt numbers,
	\item date, hour and minute,
	\item latitude and longitude.
\end{itemize}

When players access the on-line game, the tracking code written by Preloaded records machine identities. Machine IDs may be considered as individuals who actually play the game. Preloaded inserted tracking code to the on-line game, records a machine identity at each time the game was loaded, as well as the result of the game at the end of plays, and play date and time. Attempts and scores were recorded in the order of the time.

The information of locations where the machine ID accessed the game is also collected approximately at the maximum of city-block level.

\subsection{Hidden variables calculated from the original variables}
From the basic variables which are recorded when people play the game, other features that may imply useful information of how players are influenced during learning processes to get higher marks can be derived as below,

\begin{itemize}
	\item time difference,
	\item local time,
	\item gap types (no, long, short and sleep gap),
	\item a number of total plays.
\end{itemize}

The basic time information; date, hour and minute is combined together. Then, time differences between successive attempts are calculated by subtracting current game start time from its previous attempt time. Therefore, the first attempts do not have value of time differences.

\bigskip
Next, local times for each play were calculated in seconds, using the formula, "$\textit{local time} = \textit{UTCtime} + (\textit{longitude} × 24\div360),\textit{modulo}24$" \cite{stafford2016testing}. Local time would facilitate comparison of players in different time zones, thus indicating lifestyle choices. There were data that local time could not be calculated because of missing track of latitude and longitude, and those were filtered at the data cleaning task.

\bigskip
On the basis of time difference, Stafford et al. (2016) classified individuals into 4 groups, according to "the nature of the timing of their first 15 attempts at the game". First group is 'no gap' for those who had less than 15 minute break between each play. Second group is 'wake' in which players are assumed to be having a rest in their waking hours if they have "a single gap between 7 and 12 hours". Working hours is time between 5 am and 12 pm. Those who rested for between 7 and 12 hours in working hours were categorised as 'sleep'. Finally, all other individuals are classified as 'no category'.

Furthermore, for more detailed analysis, 'rest' which is defined in 'gap types' categorisation was divided with 3 types. Long gap, short gap and sleep gap were determined when players had a rest 'between 7 hours and 11 hours', 'below 15 minutes', and 'not in working hours' respectively.

\bigskip
As the term of hidden variables suggests, there are possibilities that more factors can be mined from the data set and be incrementally accommodated to it if appropriate methods are implemented.

\section{Data Deformation}
CSV format has been used as a basic data file format for previous study.

CSV is an abbreviation of Comma-Separated Values. A data record of CSV format file is a line formed by one or more elements, and commas separate those element values to be distinguishable (plain text format) \cite{shafranovich2008common}. According to Idris (2014), it is straightforward for those format to load and store data-set from the data storage onto working place; ease to generate, read and edit manually, offer versatility in most programming languages, but not efficient because exploiting plain text format "take a lot of space". This might result in consuming more time to handle such a big data set than using binary format.

Simply, the data set needs to be stored in memory unit of machine(s) where the analysis processes would operate. However, these are true only when data size is manageable. Because fitting all data-set of such a large amount of data in computer memory takes many spaces. In some cases, loading on computer memory cannot be possible depending on computer capability and setup. Thus, CSV format is not a very efficient way to manage such a large amount of data \cite{idris2014python}. To solve those problems, two approaches of being able to reduce storing spaces and of enabling faster speed for analysing were applied; converting CSV file format into Pickle format, and splitting data set into several pieces.

\subsection{Pickle file format}
Pickle file format can provide "a high level of data compression such as zip, bzip and gzip" and also faster than CSV \cite{idris2014python}, because it is "binary protocols for serializing and de-serializing a Python object structure" \cite{python2016pickle}. Furthermore, it provides on easy approach to deal with converting Python object hierarchy into a binary stream and vice versa, with the notion of 'pickling' and 'unpickling'. Moreover, pickle file format can automatically represent a large number of Python types \cite{python2016pickle}.

\bigskip
Therefore, curated data set after cleaning, accommodating, and deformation process is stored as binary file format, and for the binary file format, pickle specified for Python is used.

\subsection{Data storage and index table}
Although the big data set can be converted to binary file, it still takes a large amount of storage. And it also causes RAM memory optimisation problem. When data curation tasks are performed (of course, as well as data analysis tasks which will be discussed in the next session), processing speed became slower and slower over time. This might be because data occupies all spaces of hardware memory, and exploits virtual memory on main memory unit. Basically, RAM memory provides very high speed compared to hard disk, and it is even faster than Solid State Drive (SSD) which is often considered 'fast'. If data take all RAM memory spaces, they transfer addresses of some part of it to virtual memory. This task causes many interruptions to the tasks, and eventually decreases processing performance significantly. And depending on operating systems, Python kernel may crash.

\bigskip
Therefore, loading only necessary data to a specific task will be a solution to keep processing performance fast. Whole data set was separated by each type of variables. To secure and not to lose player information within the divided data, addresses of all data have to be indexed directing player ID. As a result of data deformation task, 15 pickle data files were generated; eventLabel, date, hour, minute, latitude, longitude, eventValue, play\_filter, comb\_time, diff\_time, local\_time, long\_gap, shor\_gap, sleep\_gap, gap\_type, and total\_plays, which are indicated by individual ID information, eventAction.

\subsection{Multiprocessing}
Because the raw data set is a large amount, the process time for data curation would take long time. Commonly, using multithreading is the easiest way to solve this operating time problem. However, unfortunately Python does not allow multiple statements at a kernel. Therefore, 
%%%%%% comment %%%%%%%%%%%%%
\begin{comment}
(Python 2001)
There are various file formats which can provide a high level of data compression.

, which is formed from 15 factors, into the data vector having like hash table

By default, the pickle data format uses a relatively compact binary representation. If you need optimal size characteristics, you can efficiently compress pickled data.


?CSV is human readable and easy to edit manually
?CSV is simple to implement and parse
?CSV is processed by almost all existing applications
?CSV provides a straightforward information schema 
?CSV is faster to handle
?CSV is smaller in size
?CSV is considered to be standard format
?CSV is compact. For XML you start tag and end tag for each column in each row. In CSV you write the column headers only once.
?CSV is easy to generate

Since, depending on your computer setup you might not be able to fit it all in memory, we'll load each class into a separate data-set, store them on disk and curate them independently. Later we'll merge them into a single data-set of manageable size.
\end{comment}

% ======================================= %
%		2.4. K-Means Clustering with Competitive Learning Algorithm
% ======================================= %
\section{K-Means Clustering with Competitive Learning Algorithm}

In order to identify learning curves of individuals, the first thing to do is to cluster players into several groups in which they show similar learning patterns. Traditional ways of identifying individual learning curves is either averaging all data of test subjects or fitting different possible underlying functions to observed population data-set \cite{newell1981mechanisms, gallistel2004learning, donner2015piecewise}

\bigskip
A well represented learning curve in psychology might be a "smooth power law of diminishing gains" \cite{donner2015piecewise}. For example, Howard (2014) tested function fitting on chess performance and verified that "power function fit is best". 

However, in contrast, Gaschler et al. (2014) stated that "the exponential function" is "better than the power function fitting" for learning curves of chess players. These different results of the same observation of chess game would result from that the power law is an artifact which averages many divergent shapes of exponential curves (Heathcote et al., 2000; Murre \& Chessa, 2011) as well as other possible underlying curves. 

Therefore, before analysing the on-line game data set, it would be a better assumption that there are many different shapes of learning curves depicting individuals' learning best, rather than only one learning curve. 
% Hence, it would be better to cluster players by similar learning patterns before identifying which curve functions will fit best on the on-line game data-set.

\bigskip
In contrast with classification tasks that classify labelled data-set, clustering is an unsupervised classification task which automatically groups similar data without predefined and labelled classes \cite{hackeling2014mastering}, and it generates the same result as classification algorithm does \cite{harrington2012machine}. 

Among several clustering methods, K-Means clustering was used with an artificial neural network algorithm, competitive learning.
%, for the analysis of the on-line game data set. 
It is because K-Means clustering algorithm in high dimensions is computationally very slow and the key method of K-Means (comparing distance in 2 and 3 dimensions) would not work for satisfying outcome in high dimensions \cite{daume2012course}.

\bigskip
Hence, there is possibility that the data-set may not properly be clustered, as the on-line game data-set is comprised of 15 dimensions. Compensating K-Means clustering with neural network algorithm would provide one of the solutions for the high dimensions data-set.

% ======================================= %
%		2.4.1 K-Means clustering
% ======================================= %
\subsection{K-Means clustering}
The name of K-Means is because it discovers k unique clusters, and the mean values of those clusters represent the centres of each cluster. The key idea of the algorithm is to compare only distances between all data and arbitrary number of cluster centres. After centroids of clusters were found, all data can be assigned to their nearest centres. In the same manner, centres of clusters can be computed after data is allocated to clusters.

Again, there are no labels or predefined information of classes in the data set. %In other word, 
Thus, it is unknown which approach has to be implemented first. The ways to tackle this are to start with initial random point, to iterate calculation of centre position, and to rearrange elements in clusters. Through iterating these three approaches until stopping criteria is satisfied, k means eventually converge to local optimisation, and comprise k number of clusters. 

\bigskip
There are two terminating criteria in K-Means clustering algorithm. The first one is using a threshold for the difference of cost functions (\ref{eq:k_means_cost_function}) through subsequent iterations (\ref{eq:threshold1}).

\begin{equation} \label{eq:threshold1}
	J_i - J_{i-1} < \theta \quad \textrm{, where} \; j \in K,
\end{equation}

and cost function $J$ is

\begin{equation} \label{eq:k_means_cost_function}
    J(\mathbf{\mu, C; D}) = \sum_n^N || x_n -\mu_{C_k} ||^2
    = \sum^K_{k=1} \sum_{i \in C_k} ||x_i - \mu_k||^2,
\end{equation}
where $\mu$ is mean of cluster, $\mathbf{D}$ is \ (the number of parameters) data-set, $\mathbf{C}$ is clusters in the data-set, $x$ is data, $N$ is the number of data, and $K$ is the number of clusters. 

The other one is to use a threshold for the difference of centre positions between successive iterations (\ref{eq:threshold2}).
\begin{equation} \label{eq:threshold2}
    x_i - x_{i-1} < \theta \quad \textrm{, where } i \; \textrm{in} \; C_k \,.
\end{equation}

\bigskip

Below is pseudo-code of K-Means clustering algorithm, 
\bigskip
\begin{algorithmic}
\FORALL{$k$ such that $ 0 \leq k < K$}
	 \STATE randomly initialise $\mu_k$
\ENDFOR
\smallskip
\WHILE{stopping criteria (\ref{eq:threshold1}) or (\ref{eq:threshold2})}
	\FORALL{$k \in K$}
		\FORALL{$i$ such that $ 0 \leq i < N$}
			\STATE $\mathbf{C}_k \leftarrow \underset{x}{\arg\min}|| \mu_k - x_i ||^2$ ,\\
		\ENDFOR
	\ENDFOR
	\smallskip
	\FORALL{$k \in K$}
		\STATE $\mu_k \leftarrow \textrm{mean}(\mathbf{C}_k)$
	\ENDFOR
\ENDWHILE
\RETURN $\mathbf{C, \mu}$
\end{algorithmic}
%After finding centers of clusters, each data are assigned to its nearest clusters.

\bigskip
At first, the positions of centroids are randomly initialised. Then, the first for loop in the while loop assigns each data to nearest clusters. The second for loop calculates the centres of clusters. By iterating these two tasks, all centroid of clusters move slightly towards the centres of each cluster, and eventually converge to local optima. For on-line game data analysis, stopping criterion (\ref{eq:threshold2}) was used. 

Moreover, this K-Means clustering algorithm was improved with artificial neural network, competitive learning algorithm, in order to cluster the on-line game data-set in high dimensions.

% ======================================= %
%		2.4.2 Competitive learning
% ======================================= %
\subsection{Competitive learning}

Competitive learning is unsupervised learning approaches in which the output neurons contend against each other to react as the one firing from the given pattern in inputs. Therefore only one unit take the winner upon all output units (\ref{fig:Competitive_Diagram}). This exclusive phenomenon in synaptic neurons is called 'winner-take-all units', and sometimes they are also called 'grandmother cells'. Which means a neuron fires on a specific stimulus. This neural networks has an advantage of clustering unlabelled data and searching the correlations of the input data. One of the most significant application of competitive learning might be vector quantisation. In which, input data-set becomes a bunch of vectors in data space, and input vectors are compressed and stored by transmitting into prototype vectors.

\begin{figure}[htpb]
    \centering
    \framebox{\parbox[t][0.7\textwidth][t]{0.95\textwidth}{
        \begin{center}
            \includegraphics[width=0.85\textwidth, height=0.65\textwidth]{Competitive_Diagram.png}
        \end{center} }}
	\caption{Competitive neuron diagram. When an input enters the network, it generates output values according to weights between an input and output neuron (blue arrows). Output neurons compete with each other (red arrows), then only one output fires on an input pattern. Output neurons are considered only having binary $0/1$ output.}
	\label{fig:Competitive_Diagram}
\end{figure}

\bigskip
It has a very similar concept to K-Means clustering algorithm. The prototype vectors can be interpreted as centroids in k-means. Besides, vector quantisation employs Euclidean metric to assign an input vector to the nearest prototype, weight vector. When input data, usually represented as a vector, are applied at the input of the network, the winner neuron indicates the appropriate class. 

If all input data are entered to the network, the input space organises a Voronoi tessellation. To be specific, Voronoi tessellation which was used for the analysis is Centroid Voronoi tessellation, in which means are positioned in each Voronoi cell (centre of mass). The weight vectors (or centroid in K-Means) are the vectors of prototypes. 

\bigskip
Output neurons $O_i$ in (\ref{eq:competitive1}) are the units having the net input in an pattern at a time,
\begin{equation}\label{eq:competitive1}
    O_i = \sum_j w_{ij}x_j = \vec{\mathbf{w_i}} \cdot \vec{\mathbf{x}},
\end{equation}
for an input vector $\mathbf{x}$. 

Winner neurons are found by (\ref{eq:competitive2}),
\begin{equation} \label{eq:competitive2}
    \vec{\mathbf{w}}_k^T\vec{\mathbf{x}}^\mu > \vec{\mathbf{w}}_i^T\vec{\mathbf{x}}^\mu \quad \textrm{for all i},
\end{equation}
where winner neuron is $\vec{\mathbf{w}}_k^T$, and $\vec{\mathbf{x}}^\mu$ is an input of pattern $\mu$.

\bigskip
(\ref{eq:competitive2}) tells winning unit is the biggest. If the weight vectors connecting between each input and output are normalized, $\vec{\mathbf{w_i}}=1$, then (\ref{eq:competitive1}) can be redefined as below,
\begin{equation} \label{eq:competitive3}
    \quad |\vec{x}^\mu - \vec{w}_k^T| \leq |\vec{x}^\mu - \vec{w}_i^T|, \quad
    \textrm{only if} \;\; |\vec{w}=1| \;\; \textrm{for all i.}
\end{equation}

\bigskip
(\ref{eq:competitive3}) shows similarity to the key idea of K-Means clustering, which only consider distances between all data and centroids.

\bigskip
Competitive learning only consider the output neuron with the maximum net value of inner product between input and weight. Biologically, output neurons are connected with other output neurons with lateral inhibition, as well as excitatory connection itself, and therefore winner takes all units.
%output neurons have a value of $\vec{w}^T\vec{x}^\mu$, thus the largest output is always win. 

\bigskip
For competitive learning, the thing to note is that weights must be normalised in order for all units to have a unit length.

% ======================================= %
%		2.4.3 Normalisation
% ======================================= %
\subsection{Normalisation}
Normalisation is important for analysing data with different scale to be compared and then to derive information in K-Means clustering \cite{bowles2015machine}. To be specific about normalisation for competitive learning, the network exploits the inner product for each input with weight vectors in order to identify winner output unit. If looking inside of (\ref{eq:competitive2}), the equation for inner product is
\begin{equation}\label{eq:inner_product}
    \vec{\mathbf{w}}^T \cdot \vec{\mathbf{x}}^\mu = \vec{\mathbf{w}}^T\vec{\mathbf{x}}^\mu \cos(\theta),
\end{equation}
with respect to the lengths of both units and a direction between input pattern and weight. Not-normalised one has no way for a criterion for competing output units with weight vectors. Because the neuron which has the largest value in length always wins. That implies the algorithm will finish without any learning or no informative outcome through iterations, in the both cases of not-normalised data-set and weight vectors.

\begin{figure}[htpb]
\begin{subfigure}{0.5\textwidth}
    \centering
    \framebox{\parbox{0.95\textwidth}{
        \begin{center}
            \includegraphics[width=0.9\textwidth, height=0.9\textwidth]{not_norm_data.png}
        \end{center} }}
    \caption{Not-normalised data with a unit weight (red arrow)}
    \label{fig:not_norm_data}
\end{subfigure}
\begin{subfigure}{0.5\textwidth}
    \framebox{\parbox{0.95\textwidth}{
        \begin{center}
            \includegraphics[width=0.9\textwidth, height=0.9\textwidth]{not_norm_weight.png}
        \end{center} }}
    \caption{Normalised data-set with not-normalised weight vectors (green arrow).}
    \label{fig:not_norm_weight}
\end{subfigure}
\caption{Examples of not-normalised data and weight in 3 dimensions. In both left and right figures, sphere represents unit length area.}
\label{fig:not-normalised}
\end{figure}

\bigskip
For the solution of that, normalising input and weight vectors simply transforms (\ref{eq:inner_product}) into the equation computing only a direction between those vectors, which tells how close weight vector is from the input vector. 

Eventually, the inner product in (\ref{eq:competitive3}) becomes the criterion which detects the shortest Euclidean distance by comparing angles between input and weight vectors, (\ref{eq:distance}).

\begin{equation}\label{eq:distance}
    \begin{split}
        \vec{\mathbf{w}}_k^T \cdot \vec{\mathbf{x}}^\mu &> 
        \vec{\mathbf{w}}_i^T \cdot \vec{\mathbf{x}}^\mu \\
        \cos(\theta_k) &\geq \cos(\theta_i).
    \end{split}
\end{equation}

The firing output neuron still has the largest value among output units when the $\theta$ is smaller than others based on the competition with proximity of the input vector.

(\ref{fig:not-normalised}) shows not-normalised issue in competitive learning. In the not-normalised data-set and weight vector, (\ref{eq:inner_product}) always compares only the length, not the closest one in the distance between data and weight vector. It is obvious that the most long vector always win, which cannot be representative for input patters. Thus weights would not move to the centre of Voronoi cell.

% ======================================= %
%		2.4.4 Procedure of the algorithm
% ======================================= %
\subsection{Procedure of the algorithm}
After normalising data-set and setting weight vectors with unit length, the competitive learning algorithm for pattern classifier exploiting (\ref{eq:competitive1}) and (\ref{eq:distance}) follows as below,

\begin{enumerate}
\item {choose weight vector with random values}: \newline
Similar to K-Means clustering, weight vectors which implies center of mass for clusters (or Voronoi cells) are initialised with random values. However, the issue of dead unit would be caused by randomly initialised weight vectors. Dead unit is the unit which is very far from any input patterns, and therefore never fires. An other problem is the optimal number of weight vectors. This problem will be discussed in the next section. The last thing to be noted is that weight vector must have unit length.

\item apply input patterns to the network in turn or in random order: \newline
After setting initial weights, input data vector as a pattern is entered to the network. It does not matter applying it in turn or in random order. The advantage of competitive learning over K-Means is that K-Means comparing all data, then must be slow, but competitive learning can run in random order input data until it approaches the sufficient learning rate. Therefore it is much faster than K-Means, on condition of how learning rate is prescribed.

\item discover a winner output unit for each input: \newline
When an input vector is applied to the network, which output unit is likely to take winner position for each normalised input pattern is found through (\ref{eq:distance}). For a given input pattern, the winner unit has the largest value among other output neurons. In other words, winner-take-all unit is the closest vector to the input vector with the smallest angle. Inhibitory and self-exitatory connection are definded biologically, but alternatively using python command, \textbf{numpy.argmax}, just maximum value is searched.

\item Update the winner neuron's weight to be close to the input vector: \newline
For each input, winner $\mathbf{w_k}$ is found among the outputs, and then it is updated to be closer by an allowed amount with learning factor $\eta$ to the current input vector. After continued update of the weight for the winner unit, weight vectors will be positioned at the center of Vornoi cells which shows similar patterns of inputs. Below is on-line and batch update rule,
	\begin{equation} \label{eq:on-line and batch}
	\begin{split}
	    \text{on-line rule}&: \Delta \vec{w}_k = \eta(\vec{x}^\mu - \vec{w_k})\\
	    \text{batch rule}&:\Delta \vec{w}_k = \eta \Sigma_{\mu \in C_k} (\vec{w_k} - \vec{x}^\mu)
	    %\text{or} \quad \quad \quad&
	\end{split}
	\end{equation}
On-line learning rule updates the change of one data point at a time. However, batch learning rule accumulates weights until all inputs in a cluster are passed to the network, and sums all of those constantly. Both converge the same centroids of clusters, but batch rule is slower than on-line learning rule which slightly fluctuates towards local optima when updating.
\end{enumerate}

As mentioned in procedure 1, choose weight vector with random values, the two possible problems; the number of clusters and dead units, of competitive learning have to be handled with proper method. The next section will introduce breakthroughs which can tackle those two issues.
% ======================================= %
%		2.4.5 Local optima and optimal number of clusters
% ======================================= %
\subsection{Local optima and optimal number of clusters}

Sometimes, a number of mean values might be randomly initialised very nearly to each other. And centroids would converge a same point in a same cluster. In this case, clusters would not describe data-set informatively. This issue is called local optima problem. Unfortunately, there is "no way of knowing what the right answer is" for the outcome of clustering algorithm, but "repeating the algorithm dozens or even more times" can increase reliability of clustering result \cite{hackeling2014mastering}. By repeating clustering algorithm several times, the starting random data points will be set differently and converge different or the same local optima as subsequent outcomes. Clustering results are compared relatively with repeated results, and the most frequent similar results can be presumed as reliable result.

%\begin{figure}[thpb]\label{fig:elbow}
%	\centering
%	\framebox{\parbox{5.5in}{ \includegraphics[scale=0.55]{elbow_method.png} }}
%	\caption{Cost values according to the different number of k}
%\end{figure}

\bigskip
Another crux of K-Means clustering is that the optimal number of clusters is unknown. There are ??? players in the on-line game data-set, and it has no predefined information of how many groups showing what the similar learning patterns are. To estimate optimal number of clusters, Elbow method with Bayes and Akaike Information Criteria (\ref{eq:AICandBIC}) was used. The criteria which can determine the number of cluster is as follow,
\
\begin{equation} \label{eq:AICandBIC}
    \begin{split}
        \textrm{Bayes Information Criteria (BIC)}:&\quad \underset{K}{\arg\min} (J_K + K\log D)\\
        \textrm{Akaike Information Criteria (AIC)}:&\quad \underset{K}{\arg\min} (J_K + 2KD).
    \end{split}
\end{equation}

\bigskip
The more a number of clusters, the less the value of the cost function, $J_K$. Because, increasing K can divide the data-set into smaller pieces of clusters than the actual number of how many clusters necessarily exists in it. Usually, using the Elbow method shows changes of the value of cost function. It goes down significantly at first some K, and suddenly slows down the change. By inspecting the point showing from dramatic to gradual change, generally the optimal number of K is detected. 

However, when only Elbow method for the on-line data-set is plotted, this inflection point is rarely found. Because all costs seem decreasing gradually, Fig.~\ref{fig:AIC_BIC_Elbow}. Therefore, BIC and AIC was exploited with Elbow method. If plotting AIC values in different number of K, it will decrease by the certain amount cost, and then start to increase. It is because $2KD$ or  $K\log D$ proportionally compensates decreasing the value of cost function for various number of K. In high dimensions, AIC criteria gives "high penalty for many clusters" \cite{daume2012course}. As a result, K value which minimizes AIC or BIC (\ref{eq:AICandBIC}) could be considered as the optimal number of clusters. 

\begin{figure}[thpb]
	\centering
	\framebox{\parbox{14cm}{
	    \begin{center}
	    \includegraphics[width=14cm]{AIC_BIC_Elbow.png}
	    \end{center} }}
	\caption{Comparison between AIC and BIC according to the different number of k. AIC are more strict method than BIC to identify the number of clusters.}
	\label{fig:AIC_BIC_Elbow}
\end{figure}

\bigskip
Fig.~\ref{fig:AIC_BIC_Elbow} shows the information of elbow method with AIC and BIC to define the number of clusters for the on-line game data-set. By these three graphs, it seems that the data-set can be clustered into n clusters. Difference between 13K and 14K is xx and, 14 K and 15 K is yy. If the number of 14 is set as a threshold for these differences, increasing K beyond 14 would not improve the result of clustering.

% ======================================= %
%		2.4.5 Dealing with dead unit
% ======================================= %
\subsection{Dealing with dead unit}
A common problem in competitive learning algorithm is dead unit issue. This is the case when weight vectors are initialised far distant from all input vectors. As they cannot fire among those which are closer to input vectors. Geometrically speaking, (\ref{fig:dead_unit}) would show precise understanding. Two arrows with different colours represent randomly initialised weight vectors. Red arrow is closer to two input groups than green weight vector. When they are threw into the network, red weight vector will move closer and closer to the centre between two groups at every iterations. Which means red weight vector always takes winner, and green weight vector will never be updated. 

\begin{figure}[htpb]
    \centering
    \framebox{\parbox[t][0.8\textwidth][t]{0.9\textwidth}{
        \begin{center}
            \includegraphics[width=0.75\textwidth, height=0.75\textwidth]{dead_unit.png}
        \end{center} }}
	\caption{An example of dead unit problem. Red and Green arrows are initialised weight before applying into the network. Green arrow is set far from both two input clusters, and it is assumed as a dead unit. Unfortunately, green arrow will never fire through the learning, and which means that input vectors are not properly clustered.}
	\label{fig:dead_unit}
\end{figure}

\begin{figure}[htpb]
    \centering
    \framebox{\parbox[t][0.7\textwidth][t]{0.95\textwidth}{
        \begin{center}
            \includegraphics[width=0.85\textwidth, height=0.65\textwidth]{dead_state.png}
        \end{center} }}
	\caption{Learning rate and existence of dead units}
	\label{fig:dead_state}
\end{figure}

In (\ref{fig:dead_state}), ??? never fired and it is the dead unit, even though neuron ?? and ?? won several time compared to other ?? output neurons.

\bigskip
There are several approaches which can tackle the dead units problem, and 4 of those;
\begin{enumerate}
    \item leaky learning (LL),
    \item add bias (AB),
    \item add noise (AN),
    \item initialisation within input space (SV),
\end{enumerate}
will be discussed.

\bigskip
First, leaky learning (LL) is the way of adjusting learning rate for both winner and lower output units. It gives loser units some chances to fire in the future, and they move towards more dense clusters. Equation of LL is as follow,
\begin{equation} \label{eq:leaky_learning}
\begin{split}
w_{ij}^{new} & = w_{ij}^{old} + \eta_{winner} (x_i - w_{ij}^{old}), \\
w_{ij}^{new} & = w_{ij}^{old} + \eta_{loser} (x_i - w_{ij}^{old}), \quad \text{where } \eta_{winner} \gg \eta_{loser} \, .
\end{split}
\end{equation}

\bigskip
The second way to deal with dead units is adding bias (AB) to winner output unis which repeatedly fire. Then, they become hard to win again and again. 
\begin{equation} \label{eq:add_bias}
\begin{split}
f_j^{new} & = f_j^{old} + \beta (z_j - f_j^{old}), \\
b_j & = \gamma (1/n - f_j), \\
w_{ij}^{new} & = w_{ij}^{old} + \alpha (x_i - w_{ij}^{old}) z_j,\\
y_j & = \Sigma_i w_{ij} x + b_j \, ,
\end{split}
\end{equation}
where $z_j$ is a selector with a value of 0 for loser or 1 for winner, $\gamma, \beta$ are constant factors, $n$ is total nodes, $f$ is firing rate of output neuron, and $b$ is bias. By varying these parameters in (\ref{eq:add_bias}), learning performance can be adjusted.

\bigskip
Next is to add noise (AN) to output neurons while they are being updated. For the on-line game data analysis, Gaussian distribution are added to all output neurons. Then, among the output units with Gaussian noises, the largest output neuron is taken as a winner unit. Because of randomness, it is possible that frequently winner neurons may not fire even in the situations when the winner and loser output units are obvious from the equation (\ref{eq:distance}).
\begin{equation} \label{eq:add_noise}
\begin{split}
y_j & = \Sigma_{i}w_{ij}x_i + \epsilon, \\
& where \,\, \epsilon \sim N(0, \sigma^2)
\end{split}
\end{equation}
This is the simplest method to escape dead units problem, by just adding noises to outputs, one of loser units may take the place to win, instead of actual winner output neuron.

\bigskip
The last approach is to initialise weight vectors with randomly sampled vectors from input space. Three approaches which are discussed above do not solve the fundamental problem of dead units, and they still have the risk that some weight vectors are set far from any cluster. Because they randomly initialise weight vectors.

However, SV set initial weights in the actual input space. Therefore, they are always positioned inside the data set. Although they may manage dead units, there is other problem that some weight vectors are initialised near to each other. If some weight vectors are set nearly, they will converge the same optima, and data set will not properly clustered. 

Thus, large (LSD) or small(SSD) values randomly sampled with Gaussian distribution are added to the initial weight vectors, so that they have enough distance from each other.

\begin{equation} \label{eq:SV}
\begin{split}
w_{ij}^{init} & = w_{ij}^{random} + \epsilon, \\
& where \,\, \epsilon \sim N(0, \sigma^2)
\end{split}
\end{equation}

\begin{figure}[htpb]
    \centering
    \framebox{\parbox[t][0.7\textwidth][t]{0.95\textwidth}{
        \begin{center}
            \includegraphics[width=0.85\textwidth, height=0.65\textwidth]{dead_states_solved.png}
        \end{center} }}
	\caption{Learning rate and and entire firing number of output neurons after using SV approach for dead units}
    \label{fig:dead_states_solved}
\end{figure}

\bigskip
In (\ref{fig:dead_states_solved}), it is shown that dead units are not exist. All output neurons fired above about 300 times, though some clusters are dominant in learning. This also give assumptions of how many individuals are belong to each cluster. It has to be noted that output firing state only give a rough estimate, as competitive algorithm exploit random point choice to compare with centroids. In addition, because there are no labelled and predefined features in the data set, there is no way to know how correct a result of clustering is. Thus, the data set is considered as unbiased, which means average from 10 iterations may represent the true value of the population.

% ======================================= %
%		2.4.5 Result
% ======================================= %
\newpage
\subsection{Centroids}

In conclusion of data curation, 1,201,516 individuals are grouped into 14 clusters as Fig.\ref{fig:centroid1}, \ref{fig:centroid2}, \ref{fig:centroid3}. Note that these are the results of truncated 15 attempts. 

\begin{figure}[htpb]
    \centering
    \framebox{\parbox[t][0.35\textheight][t]{0.95\textwidth}{
        \begin{center}
            \includegraphics[width=0.9\textwidth, height=0.3\textheight]{centroid1.png}
        \end{center} }}
	\caption{Centroids of cluster from 1 to 4}
    \label{fig:centroid1}
\end{figure}

\begin{figure}[htpb]
    \centering
    \framebox{\parbox[t][0.35\textheight][t]{0.95\textwidth}{
        \begin{center}
            \includegraphics[width=0.9\textwidth, height=0.3\textheight]{centroid2.png}
        \end{center} }}
	\caption{Centroids of cluster from 5 to 8}
    \label{fig:centroid2}
\end{figure}

\begin{figure}[htpb]
    \centering
    \framebox{\parbox[t][0.35\textheight][t]{0.95\textwidth}{
        \begin{center}
            \includegraphics[width=0.9\textwidth, height=0.3\textheight]{centroid3.png}
        \end{center} }}
	\caption{Centroids of cluster from 9 to 12}
    \label{fig:centroid3}
\end{figure}

\begin{figure}[htpb]
    \centering
    \framebox{\parbox[t][0.23\textheight][t]{0.95\textwidth}{
        \begin{center}
            \includegraphics[width=0.9\textwidth, height=0.2\textheight]{centroid4.png}
        \end{center} }}
	\caption{Centroids of cluster 13 and 14}
    \label{fig:centroid4}
\end{figure}

In the next chapter, various curves are fitted to these centroids, and which curve may properly represent learning process for each group.

% ======================================================== %
%		3. Function Fitting
% ======================================================== %
\chapter{Function Fitting}
This chapter examines the type of relationships (learning processes) between variables (attempts) and the corresponding responses (scores) players follow.  The relationships can be modelled to some functions, and these may give a clue interrelating the amount of practises and performance of the on-line game data set.

\bigskip
This process can be called 'inference' in statistical learning. Inference is different from 'prediction'. To make sure of concise understanding, both methods estimate function $f$ which may show the relationship between inputs and outputs. For an unbiased model, it can be described as
\begin{equation} \label{eq:unbiased}
    \hat{Y} = \hat{f}(X),
\end{equation}
where average of errors goes to zero, and hat symbols represent estimates. However, prediction is used for the situations that predictors (inputs) are easily obtained but responses (outputs) are not readily available. Thus $\hat{f}$ is treated as an estimator to predict currently unknown responses. On the other hand, inference has a different feature to "develop an accurate model" to "understand the relationship" between inputs and outputs \cite{james2013introduction}. In other words, it reveals a functional relationship between a set of independent variables and target variables. Thus, to find a best curve for the data set would be the task of inference.

\begin{comment}
x: predictors, independent variables, features, or variables.
y: response or dependent variable. 

The best fitting function will be identified, by fitting various functions to the data set and comparing least square error of the functions from true responses. Firstly,  on the data set of 15 attempts.
\end{comment}

\bigskip
Possible functions are introduced in the next session, and then the method of how to identify a best fitting model will be explained. Finally, models as the results of the inference task will be briefly discussed.

\section{Functions}
There are many functions which can map input variables to target responses. The easiest and most straightforward function in machine learning might be a linear model \cite{rogers2015first}. The linear model has historically been taken for a model $f$, but can the method also be applied to the on-line game data set as a function of individual learning pattern? In general, the true relationship might be more complex, and a linear function may not inference an accurate model.

\bigskip
In the same manner, a well known function in Psychology is a power function \cite{howard2014learning}. It has been controversial but considered as 'describing skill acquisition process well', whereby performance rapidly improves in early learning, decreases gradually, and reaches asymptote. Newell and Rosenbloom (1981) argued that "a single law, the power law of practice, adequately describes all of the practice data". Nevertheless, it is also argued that single exponential function may fit better for individuals than a power function, as it is produced by many averaged individual exponential functions \cite{murre2011power}.

\bigskip
Others say that individual learning curve may show an abrupt or 'aha! moment'. The untrained subjects show often "step-like increase" \cite{gallistel2004learning}, and the insight solutions are "correct more often" than "analytic solutions" for different types of problems; even in the analytic problems, (compound remote associates, anagrams, rebus puzzles, and visual aha problems). Thus, there is possibility that learning curve of the on-line game data set might show step-like appearance.

\bigskip
Therefore, it would be better to fit various possible functions and to compare each other. After that, a curve which shows the best result can be assumed the function representing performance of learning best.

% ======================================= %
%		3.1.1 Parametric Method
% ======================================= %
\subsection{Parametric Method} \label{sbs:Parametric Method}
Fitting models to the data set are involved with finding appropriate parameters of the functions. Once parameters are determined, those are substituted to the model. Then the best fitting curve can be drawn on the input variables. This model-based approach in statistical inferring needs three steps of assumption.

\bigskip
Firstly, specific shape of model has to be predefined before a learning process. For example, the on-line game data might have relationship as polynomial function in the first order,
\begin{equation} \label{eq:first_order}
    \begin{split}
        \textrm{first order model}:&\quad f(x_n;\; w_0, w_1) = w_0 + w_1 x_n,\\
        \textrm{second order model}:&\quad f(x_n;\; w_0, w_1, w_2) = w_0 + w_1, x_n, + w_1 x_n^2
    \end{split}
\end{equation}
where parameters are $w_0, w_1$ and $w_2$, $x_n$ represents data points, and $n \in \{1, 2, \cdots, n\}$. Likewise, once the model is defined, a number of model parameters are automatically determined, and set as factors which have to be mined from statistical inferring process.

\bigskip
What has to be noted next is that linearity of the model. Most models in machine learning would be practically linear function such as a first order polynomial function above. If a model is linear itself or in the parameters, the predefined function such as equation (\ref{eq:first_order}) can be alternatively simplified into vector and matrix formation,

\begin{comment}
\begin{equation} \label{eq:vector_matrix}
\begin{split}
\textrm{first order model}:&\quad f(x_n;\; \textbf{\textrm{w}}) = \textbf{\textrm{w}}^T \textbf{\textrm{x_n}}\\
\textrm{first order model}:&\quad f(\textbf{\textrm{x}};\; \textbf{\textrm{w}}) = \textbf{\textrm{X}} \textbf{\textrm{w}},
\end{split}
\end{equation}
\end{comment}

\begin{equation} \label{eq:Saa}
\begin{split}
    \textrm{vector}:&\quad f(x_n;\; \textbf{\textrm{w}}) = \textbf{\textrm{w}}^T \textbf{\textrm{x}}_n,\\
    \textrm{matrix}:&\quad f(\textbf{\textrm{x}};\; \textbf{\textrm{w}}) = \textbf{\textrm{X}} \textbf{\textrm{w}},
\end{split}
\end{equation}
where $\textbf{\textrm{w}}$ is a vector containing parameters, and $\mathbf{X}$ is a matrix consisted with data vector. For instance, a second order polynomial model has a data vector as $\textbf{\textrm{x}}_n=[1,\; x_n,\; x_n^2]^T$, and in matrix form,
\[
\begin{split}
    \mathbf{X} = 
        \left[ \begin{array}{c}
        \textbf{\textrm{x}}_1^T \\
        \textbf{\textrm{x}}_2^T \\
            \vdots \\
        \textbf{\textrm{x}}_N^T 
        \end{array} \right] =
        \left[ \begin{array}{ccc}
        1 & x_1 & x_1^2 \\
        1 & x_2 & x_2^2 \\
            \vdots \\
        1 & x_N & x_N^2
        \end{array} \right].
\end{split}
\]
Checking the linearity of the model is important, because function fitting process can be particularly simpler on linear functions than non-linear functions. In linear function, just taking partial derivatives of the loss function with respect to each parameter will result in the optimum values of parameters. The loss function will be discussed in session \ref{sbs:square_lost_function}, squared lost function.

\bigskip
Finally, parametric methods need training data to fit the model. Having collected and analysed on on-line game data, there are curated 300 data sets for each individuals, as well as centroids of 13 clusters. Theses 300 data also can be separated into two parts; training set and validation set. Training data are used to fit the model in the same way as before, and validation data are for testing the fitted curve, so as to check they are well representative of the data set. For more specific information of training and validation set, these will be explained later in the session \ref{sbs:Training_Validation}.

% ======================================= %
%		3.1.2 Functions for Single Curve
% ======================================= %
\subsection{Functions for Single Curve}
In total 4 functions which are briefly explained above are examined as possible candidates for curve fitting,

\begin{enumerate}
    \item polynomial functions in different orders
    \item exponential functions with different parameters,
    \item power functions with various parameters,
    \item step function.
\end{enumerate}

Polynomial functions from first up to five orders are trained for on-line game learning curve. First and second order were introduced in equation (\ref{eq:first_order}). Other remaining functions are as below,
\begin{equation} \label{eq:high_order}
\begin{split}
    \textrm{3rd order model}:&\quad f(x_n;\; \textbf{\textrm{w}}) = 
        w_0 + w_1 x_n + w_2 x_n^2 + w_3 x_n^3\\
    \textrm{4th order model}:&\quad f(x_n;\; \textbf{\textrm{w}}) =
        w_0 + w_1 x_n + w_2 x_n^2 + w_3 x_n^3 + w_4 x_n^4\\
    \textrm{5th order model}:&\quad f(x_n;\; \textbf{\textrm{w}}) = 
        w_0 + w_1 x_n + w_2 x_n^2 + w_3 x_n^3 + w_4 x_n^4 + w_5 x_n^5.
\end{split}
\end{equation}

Although high order polynomial functions are non-linear on function itself, they are still linear in parameters. In polynomial function, the increasing number of order, the lower cost they return. This situation is known as 'over fitting' problem in machine learning. Over fitting problem is common and must be solved in function fitting. This will be discussed in session \ref{sbs:overfitting}, overfitting.

\bigskip
Next function is exponential functions which are often considered describing individual learning curves well. Function fitting for exponential function is examined from one to four parameters.
\begin{equation} \label{eq:exponential_function}
\begin{split}
    \textrm{one parameter}:&\quad f(x_n; \; w_0) =  w_0 + e^{x_n},\\
    \textrm{two parameters}:&\quad f(x_n;\; \textbf{\textrm{w}}) = w_0 + w_1 e^{x_n},\\
    \textrm{three parameters}:&\quad f(x_n;\; \textbf{\textrm{w}}) = w_0 + w_1 e^{w_2x_n},\\
    \textrm{four parameters}:&\quad f(x_n;\; \textbf{\textrm{w}}) = w_0 + w_1 e^{w_2 (x_n+w_3)},
\end{split}
\end{equation}
where $w_0$ is asymptote, $w_1$ is slope, $w_2$ is power, and $w_3$ is delay of the exponential function. It might be thought that exponential function with four parameters will fit best among various number of parameters and training model with parameters less than four will be time consuming, because the more parameters there are, the more complexity the function can have. However, Heathcote et al. showed that exponential functions with three parameters (asymptote, slope and power) described learning result better than the three parameter power function \cite{heathcote2000power}. Therefore, in order to find the best curve fitting best to the on-line game data set, the same model with different number of parameters has to be trained and compared. Interestingly, the exponential function fitting may result in step-like shape within the range of input variables, when inputs or $w_2$ goes to $-\infty$. This case will be discussed later. 

\bigskip
The model of power law is also tested, varying the number of parameters.
\begin{equation} \label{eq:power_function}
\begin{split}
    \textrm{two parameters}:&\quad f(x_n;\; \textbf{\textrm{w}}) = w_0 + x^{w_1},\\
    \textrm{three parameters}:&\quad f(x_n;\; \textbf{\textrm{w}}) = w_0 + w_2 x^{w_1},\\
    \textrm{four parameters}:&\quad f(x_n;\; \textbf{\textrm{w}}) = w_0 + w_2 (x+w_3)^{w_1},
\end{split}
\end{equation}
where $w_0$ is asymptote, $w_1$ is power, $w_2$ is slope, and $w_3$ is delay. Power function with one parameter is omitted. Because power function with only $w_0$ parameter is first order polynomial function $f(x) = w_0+x$. Likewise exponential function, if $w_1$ goes $-infty$, it will show step-like shape, but if $w_1$ converges to $1$, the power function will become first order polynomial function.

\bigskip
Finally, players might show step-like learning curve,
\begin{equation} \label{eq:step_like}
\begin{split}
    f(x_n; \textbf{\textrm{w}}) = \left\{ \begin{array}{ll}
        w_0 & \textrm{if $x_n \geq$ break point},\\
        w_1 & \textrm{if $x_n <$ break point}.\end{array} \right.
\end{split}
\end{equation}
While above polynomial, exponential and power functions are continuous over a range of input variables, step-like function shows 'discrete' appearance which has a separate unconnected 'break point'. Thus, step-like function shows an abrupt change between a left side and right side at the break point. Step-like function is largely related to the feature of piecewise. The other other three functions are also trained on several pieces of train set.

% ======================================= %
%		3.1.3 Piecewise Function
% ======================================= %
\subsection{Piecewise Function} \label{sbs:piecewise}
Piecewise function may be continuous within pieces, but the continuity will break at the point between pieces. Pieces defines at least two equations on different parts of the input domain. Individual learning curves performed on the on-line game may contain this feature, as Gallistel (2004) argued that smooth power function (or Weibull function) cannot provide reasonable evidences of individual learning curves, and discontinuity occurs at change-points. Therefore, individual learning curves of the on-line game might be explained better through piecewise defined functions than the single curve functions.

\bigskip
For the analysis, the above four functions are combined themselves. For instance, multiple power functions constitutes a piecewise power function. In the same manner, piecewise exponential and step functions can be extended to multiple exponential and step functions respectively. Below is an example of piecewise power function having 3 parameters with 1 transition point,
\begin{equation}
\begin{split}
    f(x_n; \textbf{\textrm{w}}) = \left\{ \begin{array}{ll}
        w_0 + w_2 x_n^{w_1} &\quad \textrm{if $x_n \leq$ transition point},\\
        w_3 + w_5 x_n^{w_4} &\quad \textrm{if $x_n >$ transition point}.\end{array} \right.
\end{split}
\end{equation}
Similarly, all different functions can be combined together, such as the power function which comprises earlier part of learning and step-like or polynomial functions following transition point,
\begin{equation}
\begin{split}
    f(x_n; \textbf{\textrm{w}}) = \left\{ \begin{array}{ll}
        w_0 + w_2 x_n^{w_1} &\quad \textrm{if $x_n \leq$ transition point},\\
        w_3 + 2_4 x_n &\quad \textrm{if $x_n >$ transition point}.\end{array} \right.
\end{split}
\end{equation}
Every player may show a large variety of learning patterns, but exact learning curves are ambiguous. Thus, functions are fitted as many and various as possible, and compared with each other under a criterion, squared lost function. This criterion will be discussed in session \ref{sbs:square_lost_function}

\bigskip
Another clue about the best curve fitting in piecewise functions is identifying such transition points (or change-points) in the data set \cite{gallistel2004learning}. To identify the true discontinuities, Donner and Hardy (2015) suggested two conditions. First, a large data set is required with many individual learning curves. At the same time, those learning curves should have long enough data sequence including "potentially infrequent discontinuities". Fortunately, the on-line game data set complies with theses conditions. ??? individuals comprise the train set and almost all players have discontinuous data sequence because of unknown reasons.

In addition, in this on-line game data analysis, transition points would not only represent discontinuities of data sequences but also provide the position where squared errors in a piece wise function are minimum. The minimum cost can tell which points will result in the best curve fitting on the data set. How to find these transition points will be discussed in session \ref{abs:breaking_point}.

\bigskip
To sum up, individual learning curve may be represented as a single curve or multiple curves. Four functions; polynomial, exponential, power, and step-like function, are examined for the clustered on-line game data set. How to fit those possible models to the data set will be dealt with in the next session.

% ======================================= %
%		3.2 Method
% ======================================= %
\section{Method}
Through the previous chapter, it is discussed that several possible models might be contained in the on-line data set as individual learning curves. However, the data set seem containing noises, and they make hard to identify true parameters of the models in such high disturbance. Furthermore, even though feasible parameters are found, some criteria which measure how the trained learning curves fit well on the models are necessary. If not, there is no way to distinguish the best individual learning curve among various outcomes.

Therefore, some appropriate methods have to be operated through curve fitting process. This session introduces those methods.

\newpage

In searching for optimal learning curve from the data set, 
Each model has their own parameters. After training models on the data set, best learning  parameters  
\subsection{Squared Lost Function} \label{sbs:square_lost_function}
parametric approach (An introduction to statistical learning, 21p~24p)
\subsection{Overfitting} \label{sbs:overfitting}
\subsection{Training Set and Validation Set} \label{sbs:Training_Validation}
At first, assumption for learning processes will be tested on 14 data sets in which groups show similar learning patterns between 15 attempts and scores.
\subsection{Choice of Breaking Point} \label{abs:breaking_point}
Fig. \ref{fig:pieces} shows an example how to find the exact transition points. Firstly, entire data range is separated to $n-1$ transition points in $n$ pieces. Thus, there are three lines as the transition points with different colours (red, green, blue). Minimum 50 window in each piece is used for the example, though actual window is 10. Accordingly, transition point 1 is on 50, point 2 is on 100, and the last point is on 150, and the last piece have remained 150 of attempt range as an initial condition.

\begin{figure}[htpb]
    \centering
    \framebox{\parbox[t][0.5\textheight][t]{0.95\textwidth}{
        \begin{center}
            \includegraphics[width=0.9\textwidth, height=0.48\textheight]{piece_test.jpg}
        \end{center} }}
	\caption{Transition point shift in 4 pieces}
    \label{fig:pieces}
\end{figure}

\bigskip
In each pieces, a single function's cost is saved into a matrix. At the same time, length and staring points of each piece is also saved into another matrix. The shape of both matrices is $[\textit{\textrm{ number of pieces $\times$ number of shift of a last transition point}}]$. (\ref{eq:cost_matrix}) and (\ref{eq:length_matrix}) are an examples of the cost matrix and length matrix for 3 transition points with 4 pieces.

\begin{equation} \label{eq:cost_matrix}
\begin{split}
   \mathbf{M}= \left[\begin{array}{lll}
        1	& 	1	&	1\\
        51	&	101	&	151\\
        101	&	151	&	201\\
        151	&	201	&	251
        \end{array} \right].
\end{split}
\end{equation}

\begin{equation} \label{eq:length_matrix}
\begin{split}
   \mathbf{L}= \left[\begin{array}{lll}
        150	& 	100	&	50\\
        150	& 	100	&	50\\
        150	& 	100	&	50\\
        150	& 	100	&	50
        \end{array} \right].
\end{split}
\end{equation}

Because a start point of the first piece does not change, all elements in the first row are 1. How many iteration is needed is calculated based on the size of the last row. In this case, the last piece has initially 150 range and minimum window 50, then a number of shift in each breaking-point becomes $150 \div 50 = 3$. Therefore, cost matrix has $4\times3$ shape.

\bigskip
Using those two matrices, the optimal points which allow the piecewise function has a minimum error cost can be identified. Firstly, it is repeated that one element in each row is derived and summed. Then the total value from every iterations is checked whether is 300. 300 means the entire range of each individual data set. Then matrix L is mapped to the cost matrix, and tested that transition points are plausible. If a start point in a later row is smaller than earlier rows, the total cost value is discarded, and the costs in which each start point are greater than earlier rows from themselves are compared with each other. Finally, a minimum cost with corresponding starting points is found. Below is an pseudo-code of the algorithm to find starting point with a minimum cost.

\bigskip
\begin{algorithmic}
\STATE Initialise $l, c, s$
\FOR{i in rows of length matrix}
	\FOR{j in rows of index matrix}
		\STATE $l \leftarrow \sum \textrm{row}_{i,j}$
		\IF{$l$ is 300 and $\textrm{element}_{i+1,j} > \textrm{element}_{i,j}$}
			\STATE $c \leftarrow \sum \textrm{cost}_{i,j}$
		\ENDIF
	 \ENDFOR
\ENDFOR
\STATE $s \leftarrow \textrm{Map $\arg\min$ c into starting point matrix}$
\RETURN $s$ and $\min c$
\end{algorithmic}

\section{Curve Fittings}

%\nocite{*}
\bibliographystyle{apacite}
%\bibliographystyle{apalike}
\bibliography{references}
\end{document}
