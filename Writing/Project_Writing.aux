\relax 
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Background and Motivation}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Problem Definition}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Aims and Objectives}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Project Management}{3}}
\citation{stuart2009Axon}
\citation{stonebraker2013data}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Data Curation}{4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{stafford2014tracing}
\citation{stafford2016testing}
\citation{stafford2014tracing}
\citation{stafford2016testing}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Data Cleaning}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Data accommodating}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Original variables in the data source}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Hidden variables calculated from the original variables}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Data Deformation}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Pickle file format}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Hash table}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}K-Means Clustering with Competitive Learning Algorithm}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}K-Means clustering}{9}}
\newlabel{eq:threshold1}{{2.1}{10}}
\newlabel{eq:k_means_cost_function}{{2.2}{10}}
\newlabel{eq:threshold2}{{2.3}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Competitive learning}{11}}
\newlabel{fig:Competitive_Diagram}{{2.4.2}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Competitive neuron diagram. When an input enters the network, it generates output values according to weights between an input and output neuron (blue arrows). Output neurons compete each others (red arrows), then only one output fires on an input pattern. Output neurons are considered only having binary $0/1$ output}}{11}}
\newlabel{eq:competitive1}{{2.4}{12}}
\newlabel{eq:competitive2}{{2.5}{12}}
\newlabel{eq:competitive3}{{2.6}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Normalisation}{12}}
\newlabel{eq:inner_product}{{2.7}{13}}
\newlabel{fig:not_norm_data}{{2.4.3}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Examples of not-normalised data and weight in 3 dimensions. In both left and right figures, sphere represents unit length area. Left is the plot of original data with a weight (red arrow). The right one is the figure that has normalised data-set onto the unit length area, but not-normalised weight vectors (green arrow).}}{13}}
\newlabel{eq:distance}{{2.8}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.4}Procedure of the algorithm}{14}}
\newlabel{eq:on-line and batch}{{2.9}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.5}Local optima and optimal number of clusters}{15}}
\newlabel{eq:AICandBIC}{{2.10}{16}}
\newlabel{fig:AIC_BIC_Elbow}{{2.4.5}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Comparison between AIC and BIC according to the different number of k. AIC is more strict method than BIC to identify the number of clusters.}}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.6}Dealing with dead unit}{18}}
\newlabel{eq6}{{2.11}{18}}
\newlabel{eq7}{{2.12}{18}}
\newlabel{fig:dead_unit}{{2.4.6}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces An example of dead unit problem. Red and Green arrows are initialised weight before applying into the network. Green arrow is set far from both two input clusters, and it is assumed as a dead unit. Unfortunately, green arrow will never fire through the learning, and which means that input vectors are not properly clustered.}}{19}}
\newlabel{eq8}{{2.13}{20}}
\newlabel{eq9}{{2.14}{20}}
\newlabel{fig:states}{{2.4.6}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Comparison between AIC and BIC according to the different number of k. AIC is more strict method than BIC to identify the number of clusters.}}{21}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.7}Result}{22}}
\newlabel{fig:cluster_10}{{2.4.7}{23}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces 10 Clusters}}{23}}
\citation{*}
\bibstyle{apacite}
\bibdata{references}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Function Fitting}{24}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{bowles2015machine}{\citeauthoryear {Bowles}{Bowles}{{\APACyear {2015}}}}
\APACbibcite{bowles2015machine}{\citeauthoryear {Bowles}{Bowles}{{\APACyear {2015}}}}
\bibcite{daume2012course}{\citeauthoryear {Daum{\'e}\nobreakspace  {}III}{Daum{\'e}\nobreakspace  {}III}{{\APACyear {2012}}}}
\APACbibcite{daume2012course}{\citeauthoryear {Daum{\'e}\nobreakspace  {}III}{Daum{\'e}\nobreakspace  {}III}{{\APACyear {2012}}}}
\bibcite{donner2015piecewise}{\citeauthoryear {Donner\ \BBA{} Hardy}{Donner\ \BBA{} Hardy}{{\APACyear {2015}}}}
\APACbibcite{donner2015piecewise}{\citeauthoryear {Donner\ \BBA{} Hardy}{Donner\ \BBA{} Hardy}{{\APACyear {2015}}}}
\bibcite{gallistel2004learning}{\citeauthoryear {Gallistel, Fairhurst,{}\ \BBA{} Balsam}{Gallistel\ \BOthers {.}}{{\APACyear {2004}}}}
\APACbibcite{gallistel2004learning}{\citeauthoryear {Gallistel, Fairhurst,{}\ \BBA{} Balsam}{Gallistel\ \BOthers {.}}{{\APACyear {2004}}}}
\bibcite{gaschler2007playing}{\citeauthoryear {Gaschler, Progscha, Smallbone, Ram,{}\ \BBA{} Bilalic}{Gaschler\ \BOthers {.}}{{\APACyear {2007}}}}
\APACbibcite{gaschler2007playing}{\citeauthoryear {Gaschler, Progscha, Smallbone, Ram,{}\ \BBA{} Bilalic}{Gaschler\ \BOthers {.}}{{\APACyear {2007}}}}
\bibcite{hackeling2014mastering}{\citeauthoryear {Hackeling}{Hackeling}{{\APACyear {2014}}}}
\APACbibcite{hackeling2014mastering}{\citeauthoryear {Hackeling}{Hackeling}{{\APACyear {2014}}}}
\bibcite{harrington2012machine}{\citeauthoryear {Harrington}{Harrington}{{\APACyear {2012}}}}
\APACbibcite{harrington2012machine}{\citeauthoryear {Harrington}{Harrington}{{\APACyear {2012}}}}
\bibcite{heathcote2000power}{\citeauthoryear {Heathcote, Brown,{}\ \BBA{} Mewhort}{Heathcote\ \BOthers {.}}{{\APACyear {2000}}}}
\APACbibcite{heathcote2000power}{\citeauthoryear {Heathcote, Brown,{}\ \BBA{} Mewhort}{Heathcote\ \BOthers {.}}{{\APACyear {2000}}}}
\bibcite{howard2014learning}{\citeauthoryear {Howard}{Howard}{{\APACyear {2014}}}}
\APACbibcite{howard2014learning}{\citeauthoryear {Howard}{Howard}{{\APACyear {2014}}}}
\bibcite{idris2014python}{\citeauthoryear {Idris}{Idris}{{\APACyear {2014}}}}
\APACbibcite{idris2014python}{\citeauthoryear {Idris}{Idris}{{\APACyear {2014}}}}
\bibcite{murre2011power}{\citeauthoryear {Murre\ \BBA{} Chessa}{Murre\ \BBA{} Chessa}{{\APACyear {2011}}}}
\APACbibcite{murre2011power}{\citeauthoryear {Murre\ \BBA{} Chessa}{Murre\ \BBA{} Chessa}{{\APACyear {2011}}}}
\bibcite{newell1981mechanisms}{\citeauthoryear {Newell\ \BBA{} Rosenbloom}{Newell\ \BBA{} Rosenbloom}{{\APACyear {1981}}}}
\APACbibcite{newell1981mechanisms}{\citeauthoryear {Newell\ \BBA{} Rosenbloom}{Newell\ \BBA{} Rosenbloom}{{\APACyear {1981}}}}
\bibcite{python2016pickle}{\citeauthoryear {on-line Python\nobreakspace  {}document}{on-line Python\nobreakspace  {}document}{{\APACyear {{\bibnodate {}}}}}}
\APACbibcite{python2016pickle}{\citeauthoryear {on-line Python\nobreakspace  {}document}{on-line Python\nobreakspace  {}document}{{\APACyear {{\bibnodate {}}}}}}
\@writefile{toc}{\contentsline {chapter}{References}{25}}
\bibcite{shafranovich2008common}{\citeauthoryear {Shafranovich}{Shafranovich}{{\APACyear {2008}}}}
\APACbibcite{shafranovich2008common}{\citeauthoryear {Shafranovich}{Shafranovich}{{\APACyear {2008}}}}
\bibcite{stafford2014tracing}{\citeauthoryear {Stafford\ \BBA{} Dewar}{Stafford\ \BBA{} Dewar}{{\APACyear {2014}}}}
\APACbibcite{stafford2014tracing}{\citeauthoryear {Stafford\ \BBA{} Dewar}{Stafford\ \BBA{} Dewar}{{\APACyear {2014}}}}
\bibcite{stafford2016testing}{\citeauthoryear {Stafford\ \BBA{} Haasnoot}{Stafford\ \BBA{} Haasnoot}{{\APACyear {2016}}}}
\APACbibcite{stafford2016testing}{\citeauthoryear {Stafford\ \BBA{} Haasnoot}{Stafford\ \BBA{} Haasnoot}{{\APACyear {2016}}}}
\bibcite{stonebraker2013data}{\citeauthoryear {Stonebraker\ \BOthers {.}}{Stonebraker\ \BOthers {.}}{{\APACyear {2013}}}}
\APACbibcite{stonebraker2013data}{\citeauthoryear {Stonebraker\ \BOthers {.}}{Stonebraker\ \BOthers {.}}{{\APACyear {2013}}}}
\bibcite{stuart2009Axon}{\citeauthoryear {Stuart}{Stuart}{{\APACyear {2009}}}}
\APACbibcite{stuart2009Axon}{\citeauthoryear {Stuart}{Stuart}{{\APACyear {2009}}}}
