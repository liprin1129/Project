{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Seperate File for Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd #data analysis\n",
    "# import os #file/directory operations\n",
    "import multiprocessing as mp\n",
    "import DC_Pickle as dcp\n",
    "# from six.moves import cPickle as pickle\n",
    "\n",
    "datafile='../../data/v2merged_test.csv' #full dataset\n",
    "df=pd.read_csv(datafile)\n",
    "print(\"\\n - importing data... \")\n",
    "        \n",
    "groups = df.groupby('ga:eventAction')\n",
    "print(\"\\n - Data has {0} individualas with {1} data\".format(len(groups), len(df)))\n",
    "\n",
    "cores = mp.cpu_count() # number of cores\n",
    "\n",
    "dcp.make_folders(\"../../data/pickles/multiprocessing_test/\") # grouping data based on core number\n",
    "print(\"\\n - Seperate data into {0} groups including individuals\".format(cores, round(len(groups)/cores)))\n",
    "\n",
    "dcp.seperate_indi(groups, cores, \"../../data/pickles/multiprocessing_test/process{0}.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# sleepgap.py를 실행해 result_sleepgap_15.csv 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd #data analysis\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Process, Queue\n",
    "import DC_Pickle as dcp\n",
    "import DC_filter as dcf\n",
    "t0 = time.clock() # initial time\n",
    "cores= mp.cpu_count() #processes raw data in batches (required because data>ram)\n",
    "loding = True\n",
    "\n",
    "def process_df(queue, file_name):\n",
    "    err_players = []\n",
    "    \n",
    "    df = dcp.open_Pickle(file_name)\n",
    "    df = df.drop('Unnamed: 0', axis=1)\n",
    "    \n",
    "    new_df = df.groupby('ga:eventAction').apply(dcf.add_TotalPlays)\n",
    "    new_df = new_df[new_df['total_plays']>14]\n",
    "    new_df = new_df[new_df['ga:eventLabel']<301]\n",
    "    dcf.check_Discon(new_df, err_players)\n",
    "                  \n",
    "    new_df = dcf.add_DiffTime(new_df)\n",
    "    new_df = dcf.add_GapType(new_df)\n",
    "    #df = filter_time(df) # 이건 안하는게 좋겠다. attemps를 지우니까.\n",
    "    new_df=new_df.groupby('ga:eventAction').apply(dcf.add_GapCategory)\n",
    "                  \n",
    "    queue.put([new_df, err_players])\n",
    "\n",
    "## Execute! ##\n",
    "print('\\n -  Data Loading...')\n",
    "\n",
    "## start multiprocessing\n",
    "for i in range(cores):\n",
    "    set_filename = \"../../data/pickles/multiprocessing_test/process{0}.pickle\".format(i)\n",
    "    set_pros_name = \"core{0}\".format(i)\n",
    "    set_q_name = \"q{0}\".format(i)\n",
    "\n",
    "    globals()[set_q_name] = Queue()\n",
    "    globals()[set_pros_name] = Process(target=process_df, args=(eval(set_q_name), set_filename,))\n",
    "    #globals()[set_pros_name] = Process(target=process_df, args=(eval(set_q_name), set_filename, eval(error_name),))\n",
    "\n",
    "    eval(set_pros_name).start()\n",
    "    print('core{0} start'.format(i))\n",
    "    time.sleep(1)\n",
    "\n",
    "print('\\n -  Data filtering...')\n",
    "\n",
    "## get returned value from multiprocessing\n",
    "df = pd.DataFrame()\n",
    "err = pd.DataFrame()\n",
    "for i in range(cores):\n",
    "    set_q_name = \"q{0}\".format(i) # queue name\n",
    "    set_pros_name = \"core{}\".format(i) # process name\n",
    "    set_df_name = \"df{0}\".format(i) # data frame name of each process\n",
    "    error_name = \"error_players{0}\".format(i) # player name with error attempts\n",
    "    \n",
    "    locals()[set_df_name], locals()[error_name] = eval(set_q_name).get() # get from queue\n",
    "\n",
    "    df = df.append(eval(set_df_name)) # concat each dfs\n",
    "    err = err.append(eval(error_name)) # np.hstack((err_plys, eval(error_name))) # concat each error players\n",
    "    #df = df.drop('level_0', axis=1)\n",
    "    \n",
    "    eval(set_q_name).close()\n",
    "    eval(set_pros_name).join()\n",
    "    print('core{0} close'.format(i))\n",
    "    time.sleep(1)\n",
    "\n",
    "[df, err] = dcf.data_PostProcess(df, err)\n",
    "\n",
    "print(\"\\n - saving processed data...\\n {0} plays, {1}players\".format(len(df), len(df.groupby('eventAction'))))\n",
    "\n",
    "df.to_csv('../../data/filtered_data_test.csv')\n",
    "err.to_csv('../../data/error_players_test.csv')\n",
    "print(\"\\n - process terminal.\")\n",
    "print(\"Run time: \", time.clock()-t0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "print(err_plys)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hash table style\n",
    "\n",
    "import pandas as pd #data analysis\n",
    "import numpy as np #numerical function\n",
    "from six.moves import cPickle as pickle\n",
    "df=pd.read_csv('filtered_data_test.csv')\n",
    "print(df.columns)\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "df = df.drop('index', axis=1)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make a matrix that will contain each column of each player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np #numerical function\n",
    "import pandas as pd #data analysis\n",
    "import os #file/directory operations\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "df=pd.read_csv('filtered_data_test.csv')\n",
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def spt_ColData(data_frame, col_name): # seperate columns into each matrix\n",
    "    '''\n",
    "    def group_Len(data, len_vec): # inner function\n",
    "        len_vec.append(len(data))\n",
    "\n",
    "    group_len = []\n",
    "    groups = df.groupby('ga:eventAction') # grouping\n",
    "    groups.apply(group_Len, group_len) # get length of each player\n",
    "\n",
    "    #print(max(group_len), len(groups)) # row = attemt numbers, column = players\n",
    "    '''\n",
    "    groups = df.groupby('eventAction') # grouping\n",
    "    col_matrix = np.ones((301, len(groups)))*np.nan # make a matrix with player attempts size.\n",
    "    \n",
    "    #if type(group[col_name]) == str:\n",
    "    #col_matrix = np.chararray((301, len(groups)), itemsize=37)\n",
    "    #col_matrix = np.zeros((301, len(groups)))\n",
    "\n",
    "    count = 0\n",
    "    for name, group in groups:\n",
    "        idx = np.array(group['eventLabel'])-1\n",
    "        col_matrix[idx, count] = group[col_name]\n",
    "        count = count + 1\n",
    "    #print('Matrix size:', np.shape(col_matrix))\n",
    "    return col_matrix\n",
    "\n",
    "def make_folders(set_dir_name):\n",
    "    if os.path.exists(set_dir_name):\n",
    "      # You may override by setting force=True.\n",
    "      print('%s folder already present - Skipping pickling.' % set_dir_name)\n",
    "    else:\n",
    "        try:\n",
    "            os.makedirs(set_dir_name)\n",
    "        except Exception as e:\n",
    "            print('Unable to make', set_dir_name, ':', e)\n",
    "            return\n",
    "\n",
    "def make_Pickle(set_data, set_filename, force = False):\n",
    "    if os.path.exists(set_filename) and not force:\n",
    "        # You may override by setting force=True.  \n",
    "        print('%s pickle already present - Skipping pickling.' % set_filename)\n",
    "    else :\n",
    "        try :\n",
    "            with open(set_filename, 'wb') as f:\n",
    "                pickle.dump(set_data, f, pickle.HIGHEST_PROTOCOL)\n",
    "        except Exception as e :\n",
    "            print(\"Unable to save data to\", set_filename, ': ', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(df.columns)\n",
    "mm = spt_ColData(df, 'eventLabel')\n",
    "#mm = mm[:15, :]\n",
    "print(mm[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### conver to picke except 'eventAction' and 'comb_time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def colToPickle():\n",
    "    set_folder_name = 'pickles/seperate_origin/'\n",
    "    make_folders(set_folder_name)    \n",
    "    \n",
    "    for col_name in np.array(df.columns):\n",
    "        if not (col_name == 'eventAction' or col_name == 'comb_time'): # conver to picke except 'eventAction' and 'comb_time'\n",
    "            set_mat = col_name\n",
    "            print(col_name)\n",
    "            locals()[set_mat] = spt_ColData(df, col_name)\n",
    "            make_Pickle(eval(set_mat), 'pickles/seperate_origin/{0}'.format(col_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colToPickle()\n",
    "\n",
    "groups = df.groupby('eventAction')\n",
    "names = pd.DataFrame({'ID':groups.grouper.result_index.values})\n",
    "make_Pickle(names, 'pickles/seperate_origin/eventAction')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
