{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Seperate File for Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd #data analysis\n",
    "# import os #file/directory operations\n",
    "import multiprocessing as mp\n",
    "import DC_Pickle as dcp\n",
    "# from six.moves import cPickle as pickle\n",
    "\n",
    "datafile='../../data/v2merged.csv' #full dataset\n",
    "df=pd.read_csv(datafile)\n",
    "print(\"\\n - importing data... \")\n",
    "        \n",
    "groups = df.groupby('ga:eventAction')\n",
    "print(\"\\n - Data has {0} individualas with {1} data...\".format(len(groups), len(df)))\n",
    "\n",
    "cores = mp.cpu_count() # number of cores\n",
    "\n",
    "dcp.make_folders(\"../../data/pickles/multiprocessing_origin/\") # grouping data based on core number\n",
    "\n",
    "print(\"\\n - Seperate data into {0} groups including {1} individuals...\".format(cores, round(len(groups)/cores)))\n",
    "\n",
    "dcp.seperate_indi(groups, cores, \"../../data/pickles/multiprocessing_origin/process{0}.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Filtering data using multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd #data analysis\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Process, Queue\n",
    "import DC_Pickle as dcp\n",
    "import DC_filter as dcf\n",
    "t0 = time.clock() # initial time\n",
    "cores= mp.cpu_count() #processes raw data in batches (required because data>ram)\n",
    "\n",
    "def process_df(queue, file_name):\n",
    "    err_players = []\n",
    "    \n",
    "    df = dcp.open_Pickle(file_name)\n",
    "    df = df.drop('Unnamed: 0', axis=1)\n",
    "    \n",
    "    new_df = df.groupby('ga:eventAction').apply(dcf.add_TotalPlays)\n",
    "    new_df = new_df[new_df['total_plays']>14]\n",
    "    new_df = new_df[new_df['ga:eventLabel']<301]\n",
    "    dcf.check_Discon(new_df, err_players)\n",
    "                  \n",
    "    new_df = dcf.add_DiffTime(new_df)\n",
    "    new_df = dcf.add_GapType(new_df)\n",
    "    #df = filter_time(df) # 이건 안하는게 좋겠다. attemps를 지우니까.\n",
    "    new_df=new_df.groupby('ga:eventAction').apply(dcf.add_GapCategory)\n",
    "                  \n",
    "    queue.put([new_df, err_players])\n",
    "\n",
    "## Execute! ##\n",
    "print('\\n -  Data Loading...')\n",
    "\n",
    "## start multiprocessing\n",
    "for i in range(cores):\n",
    "    set_filename = \"../../data/pickles/multiprocessing_origin/process{0}.pickle\".format(i)\n",
    "    set_pros_name = \"core{0}\".format(i)\n",
    "    set_q_name = \"q{0}\".format(i)\n",
    "\n",
    "    globals()[set_q_name] = Queue()\n",
    "    globals()[set_pros_name] = Process(target=process_df, args=(eval(set_q_name), set_filename,))\n",
    "\n",
    "    eval(set_pros_name).start()\n",
    "    print('core{0} start'.format(i))\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "print('\\n -  Data filtering...')\n",
    "\n",
    "## get returned value from multiprocessing\n",
    "df = pd.DataFrame()\n",
    "err = pd.DataFrame()\n",
    "for i in range(cores):\n",
    "    set_q_name = \"q{0}\".format(i) # queue name\n",
    "    set_pros_name = \"core{}\".format(i) # process name\n",
    "    set_df_name = \"df{0}\".format(i) # data frame name of each process\n",
    "    error_name = \"error_players{0}\".format(i) # player name with error attempts\n",
    "    \n",
    "    locals()[set_df_name], locals()[error_name] = eval(set_q_name).get() # get from queue\n",
    "\n",
    "    df = df.append(eval(set_df_name)) # concat each dfs\n",
    "    err = err.append(eval(error_name)) # np.hstack((err_plys, eval(error_name))) # concat each error players\n",
    "    #df = df.drop('level_0', axis=1)\n",
    "    \n",
    "    eval(set_q_name).close()\n",
    "    eval(set_pros_name).join()\n",
    "    print('core{0} close'.format(i))\n",
    "    time.sleep(1)\n",
    "\n",
    "[df, err] = dcf.data_PostProcess(df, err)\n",
    "\n",
    "print(\"\\n - saving processed data...\\n {0} plays, {1}players\".format(len(df), len(df.groupby('eventAction'))))\n",
    "\n",
    "df.to_csv('../../data/filtered_data_origin.csv')\n",
    "err.to_csv('../../data/error_players_origin.csv')\n",
    "\n",
    "print(\"\\n - process terminal (Run time:{0})\".format(time.clock()-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Save with Hash Table Style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make a matrix that will contain each column of each player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import numpy as np #numerical function\n",
    "import pandas as pd #data analysis\n",
    "#import os #file/directory operations\n",
    "import DC_Pickle as dcp\n",
    "#from six.moves import cPickle as pickle\n",
    "\n",
    "df=pd.read_csv('../../data/filtered_data_test.csv')\n",
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### temporarily check discontinous individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indi_idx = 29\n",
    "tc_attempts = dcp.seperate_ColData(df, 'eventLabel')\n",
    "tc_id = df.groupby('eventAction').grouper.result_index\n",
    "\n",
    "print(\"- test check discontinous individual - \\n ID:{0}, \\n Data:\\n{1}\"\n",
    "      .format(tc_id[indi_idx], tc_attempts[:, indi_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conver data set to seperated pickle data file except 'comb_time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dcp.colToPickle(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
